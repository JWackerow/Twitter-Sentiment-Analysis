{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "by8FWYEEmHb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd9206a-82c7-4017-dca7-0714c3187e16"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Embedding, Dense, Dropout, Conv1D, GlobalMaxPooling1D, Flatten\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "\r\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.multiclass import OneVsRestClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "\r\n",
        "from gensim.utils import simple_preprocess\r\n",
        "\r\n",
        "import re\r\n",
        "\r\n",
        "import matplotlib as plt\r\n",
        "\r\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D00SchI8qu-B",
        "outputId": "3d47b634-c84c-42c8-cec5-1cb28563d8bc"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5cfA01Wq8xO"
      },
      "source": [
        "data = pd.read_csv(r'/content/gdrive/My Drive/Datasets/Tweets.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEDmgicftvM6",
        "outputId": "ef4a1f04-fbcb-49f9-8169-5fdced59a225"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "odK2kVMItWHN",
        "outputId": "c54b2e8a-3906-41ba-b82d-18d7a74fcb63"
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[2 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vxj7xnAstdpH",
        "outputId": "d7fca7c2-eea0-42c0-db94-8ecce0b354f0"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14640 entries, 0 to 14639\n",
            "Data columns (total 15 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   tweet_id                      14640 non-null  int64  \n",
            " 1   airline_sentiment             14640 non-null  object \n",
            " 2   airline_sentiment_confidence  14640 non-null  float64\n",
            " 3   negativereason                9178 non-null   object \n",
            " 4   negativereason_confidence     10522 non-null  float64\n",
            " 5   airline                       14640 non-null  object \n",
            " 6   airline_sentiment_gold        40 non-null     object \n",
            " 7   name                          14640 non-null  object \n",
            " 8   negativereason_gold           32 non-null     object \n",
            " 9   retweet_count                 14640 non-null  int64  \n",
            " 10  text                          14640 non-null  object \n",
            " 11  tweet_coord                   1019 non-null   object \n",
            " 12  tweet_created                 14640 non-null  object \n",
            " 13  tweet_location                9907 non-null   object \n",
            " 14  user_timezone                 9820 non-null   object \n",
            "dtypes: float64(2), int64(2), object(11)\n",
            "memory usage: 1.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYcH7zrR5b3V"
      },
      "source": [
        "stop_words = stopwords.words(\"english\")\r\n",
        "stemmer = PorterStemmer()\r\n",
        "\r\n",
        "def preprocess_text(doc, remove_handles=True, remove_stopwords=False, stop_words=list(), stem=True):\r\n",
        "  \r\n",
        "  if remove_handles:\r\n",
        "    doc = re.sub(\"[@](\\w|\\d[_])+\", \"\", doc, flags=re.I)\r\n",
        "  # format numbers so they all match. To avoid being confused as hashtags in tweets, I use 'num' token instead of #\r\n",
        "  doc = re.sub('\\d+', \"num\", doc)\r\n",
        "  # use gensim's simple_preprocess to clean up text\r\n",
        "  doc = simple_preprocess(doc=doc, deacc=True)\r\n",
        "\r\n",
        "  if remove_stopwords or stem:\r\n",
        "    doc_hold = list()\r\n",
        "    for token in doc:\r\n",
        "      if remove_stopwords:\r\n",
        "        if token not in stop_words:\r\n",
        "          if stem:\r\n",
        "            doc_hold.append(stemmer.stem(token))\r\n",
        "      elif stem:\r\n",
        "        doc_hold.append(stemmer.stem(token))\r\n",
        "      else:\r\n",
        "        doc_hold.append(token)\r\n",
        "\r\n",
        "    # If the entire tweet happened to be stop words, replace with \"stopword\" token\r\n",
        "    if len(doc_hold) == 0:\r\n",
        "      doc_hold.append(\"stopword\")\r\n",
        "    doc = ' '.join(doc_hold)\r\n",
        "  \r\n",
        "  return doc"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WJZAd084iB3"
      },
      "source": [
        "# Clean up/preprocess tweet text\r\n",
        "texts = data.text.apply(lambda x: preprocess_text(x, remove_handles=True, remove_stopwords=False, stop_words=stop_words, stem=True))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX1YijH9FT6N",
        "outputId": "75e55e6d-d592-4b46-dda8-58d0bb9e40a8"
      },
      "source": [
        "texts[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                            what said\n",
              "1           plu you ve ad commerci to the experi tacki\n",
              "2         didn today must mean need to take anoth trip\n",
              "3    it realli aggress to blast obnoxi entertain in...\n",
              "4                 and it realli big bad thing about it\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPXrpCFl-aE-"
      },
      "source": [
        "# set y and encode labels\r\n",
        "y = data.airline_sentiment\r\n",
        "# Encode the target (sentiment) labels\r\n",
        "le = LabelEncoder()\r\n",
        "y = le.fit_transform(y)\r\n",
        "\r\n",
        "# Split data into training and testing\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, y, test_size=.2, random_state=1)\r\n",
        "\r\n",
        "# Set max vocab size, oov-token, and fit tokenizer\r\n",
        "max_vocab_size = 10000\r\n",
        "tokenizer = Tokenizer(num_words=max_vocab_size, filters='!\"$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', oov_token='OOV')\r\n",
        "tokenizer.fit_on_texts(X_train)\r\n",
        "\r\n",
        "# Convert training and test data to sequences\r\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\r\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\r\n",
        "# Convert all texts to sequences to use for grid search hyperparameter tuning\r\n",
        "X = tokenizer.texts_to_sequences(texts)\r\n",
        "\r\n",
        "# Set max sequence length\r\n",
        "max_seq_len = max([len(i) for i in X])\r\n",
        "# Pad sequences\r\n",
        "X_train = pad_sequences(X_train, maxlen=max_seq_len, padding=\"post\")\r\n",
        "X_test = pad_sequences(X_test, maxlen=max_seq_len, padding=\"post\")\r\n",
        "X = pad_sequences(X, maxlen=max_seq_len, padding='post')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LtUH5rvGWEe"
      },
      "source": [
        "**Use grid search to tune hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apM6emVA_Ri9"
      },
      "source": [
        "def create_model(filters=256, kernel_size=5, rate=.2):\r\n",
        "  input_dim = len(tokenizer.word_index) + 1\r\n",
        "  model = Sequential([\r\n",
        "                        Embedding(input_dim=input_dim, output_dim=128),\r\n",
        "                        Conv1D(filters, kernel_size),\r\n",
        "                        GlobalMaxPooling1D(),\r\n",
        "                        Flatten(),\r\n",
        "                        Dropout(rate),\r\n",
        "                        Dense(64, activation='relu'),\r\n",
        "                        Dropout(rate),\r\n",
        "                        Dense(8, activation='relu'),\r\n",
        "                        Dropout(rate),\r\n",
        "                        Dense(3, activation='softmax')])\r\n",
        "\r\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "  return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzyU0CMRmyl0"
      },
      "source": [
        "model = KerasClassifier(build_fn=create_model, epochs=5, validation_split=.2)\r\n",
        "param_grid = {'filters' : [ 256, 512], 'kernel_size' : [ 3, 4, 5, 6], 'rate' : [.2, .3, .4, .5]}\r\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='f1_micro', n_jobs=-1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L6HdZjaAVOw",
        "outputId": "ec6db355-9387-4a89-a188-7fb6bf23efac"
      },
      "source": [
        "history = grid.fit(X=X, y=y)\r\n",
        "print(grid.best_params_)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "366/366 [==============================] - 21s 55ms/step - loss: 0.9554 - accuracy: 0.5630 - val_loss: 0.5491 - val_accuracy: 0.7886\n",
            "Epoch 2/5\n",
            "366/366 [==============================] - 20s 53ms/step - loss: 0.6830 - accuracy: 0.7195 - val_loss: 0.5091 - val_accuracy: 0.8145\n",
            "Epoch 3/5\n",
            "366/366 [==============================] - 20s 53ms/step - loss: 0.5826 - accuracy: 0.7614 - val_loss: 0.5008 - val_accuracy: 0.8139\n",
            "Epoch 4/5\n",
            "366/366 [==============================] - 20s 54ms/step - loss: 0.4916 - accuracy: 0.7972 - val_loss: 0.5322 - val_accuracy: 0.8016\n",
            "Epoch 5/5\n",
            "366/366 [==============================] - 20s 53ms/step - loss: 0.4294 - accuracy: 0.8238 - val_loss: 0.6020 - val_accuracy: 0.7995\n",
            "{'filters': 256, 'kernel_size': 5, 'rate': 0.5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H27vaAGHTNo"
      },
      "source": [
        "**Final Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcTF8dnxtIOb"
      },
      "source": [
        "input_dim = len(tokenizer.word_index) + 1\r\n",
        "model = Sequential([\r\n",
        "                        Embedding(input_dim=input_dim, output_dim=128),\r\n",
        "                        Conv1D(256, 5),\r\n",
        "                        GlobalMaxPooling1D(),\r\n",
        "                        Flatten(),\r\n",
        "                        Dropout(.5),\r\n",
        "                        Dense(64, activation='relu'),\r\n",
        "                        Dropout(.5),\r\n",
        "                        Dense(8, activation='relu'),\r\n",
        "                        Dropout(.5),\r\n",
        "                        Dense(3, activation='softmax')\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfN9BylbFHO-",
        "outputId": "3d56d439-edc9-4dd1-9156-2610474cbd9b"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=15)\r\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)\r\n",
        "print(f1_score(y_test, y_pred, average='micro'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "183/183 [==============================] - 16s 83ms/step - loss: 0.9145 - accuracy: 0.6151\n",
            "Epoch 2/15\n",
            "183/183 [==============================] - 15s 81ms/step - loss: 0.6797 - accuracy: 0.6792\n",
            "Epoch 3/15\n",
            "183/183 [==============================] - 15s 83ms/step - loss: 0.5527 - accuracy: 0.7617\n",
            "Epoch 4/15\n",
            "183/183 [==============================] - 15s 82ms/step - loss: 0.4834 - accuracy: 0.7872\n",
            "Epoch 5/15\n",
            "183/183 [==============================] - 15s 84ms/step - loss: 0.4230 - accuracy: 0.8239\n",
            "Epoch 6/15\n",
            "183/183 [==============================] - 16s 86ms/step - loss: 0.3675 - accuracy: 0.8535\n",
            "Epoch 7/15\n",
            "183/183 [==============================] - 15s 85ms/step - loss: 0.3192 - accuracy: 0.8739\n",
            "Epoch 8/15\n",
            "183/183 [==============================] - 15s 83ms/step - loss: 0.3011 - accuracy: 0.8716\n",
            "Epoch 9/15\n",
            "183/183 [==============================] - 15s 83ms/step - loss: 0.2659 - accuracy: 0.8933\n",
            "Epoch 10/15\n",
            "183/183 [==============================] - 16s 85ms/step - loss: 0.2683 - accuracy: 0.8902\n",
            "Epoch 11/15\n",
            "183/183 [==============================] - 16s 86ms/step - loss: 0.2636 - accuracy: 0.8933\n",
            "Epoch 12/15\n",
            "183/183 [==============================] - 15s 84ms/step - loss: 0.2422 - accuracy: 0.8977\n",
            "Epoch 13/15\n",
            "183/183 [==============================] - 15s 85ms/step - loss: 0.2372 - accuracy: 0.9000\n",
            "Epoch 14/15\n",
            "183/183 [==============================] - 15s 83ms/step - loss: 0.2242 - accuracy: 0.9000\n",
            "Epoch 15/15\n",
            "183/183 [==============================] - 15s 83ms/step - loss: 0.2283 - accuracy: 0.9030\n",
            "0.7681010928961749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkHC3tSSkgGa"
      },
      "source": [
        "**OneVsRest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu8c9QyZnLhG",
        "outputId": "81095cfe-079b-49ea-9815-a53007d4cce4"
      },
      "source": [
        "# Create pipeline for preprocessing and classifier\r\n",
        "pipe = Pipeline(steps=([('tfidf', TfidfVectorizer(strip_accents='unicode')), ('classifier', OneVsRestClassifier(LogisticRegression(max_iter=250, random_state=0)))]))\r\n",
        "# Use grid search to optimize best hyperparameters\r\n",
        "param_grid = {'classifier__estimator__C': [2, 3, 4, 5, 6], 'classifier__estimator__penalty' : ['l1', 'l2']}\r\n",
        "grid = GridSearchCV(estimator=pipe, param_grid=param_grid, scoring='f1_micro', n_jobs=-1)\r\n",
        "grid.fit(data.text, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('tfidf',\n",
              "                                        TfidfVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.float64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        norm='l2',\n",
              "                                                        preprocessor=None,\n",
              "                                                        smooth_idf=True,\n",
              "                                                        stop_words=None,\n",
              "                                                        strip_...\n",
              "                                                                                         multi_class='auto',\n",
              "                                                                                         n_jobs=None,\n",
              "                                                                                         penalty='l2',\n",
              "                                                                                         random_state=0,\n",
              "                                                                                         solver='lbfgs',\n",
              "                                                                                         tol=0.0001,\n",
              "                                                                                         verbose=0,\n",
              "                                                                                         warm_start=False),\n",
              "                                                            n_jobs=None))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'classifier__estimator__C': [2, 3, 4, 5, 6],\n",
              "                         'classifier__estimator__penalty': ['l1', 'l2']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1_micro', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F_c7emGnmm1",
        "outputId": "131278d8-f0af-46cc-9a28-240d8c00179f"
      },
      "source": [
        "# Print best parameters\r\n",
        "print(grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'classifier__estimator__C': 4, 'classifier__estimator__penalty': 'l2'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK4QkPgRoQvQ",
        "outputId": "694f561b-54db-4d10-c64b-a38c9fcc422c"
      },
      "source": [
        "# Split texts into training and testing again since we are using the TdidftVectorizer this time\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, y, test_size=.2, random_state=1)\r\n",
        "\r\n",
        "# build and train model with best hyperparameters\r\n",
        "model = Pipeline(steps=([('tfidf', TfidfVectorizer(strip_accents='unicode')), ('classifier', OneVsRestClassifier(LogisticRegression(C=4, max_iter=250, random_state=0)))]))\r\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents='unicode',\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patt...\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 OneVsRestClassifier(estimator=LogisticRegression(C=4,\n",
              "                                                                  class_weight=None,\n",
              "                                                                  dual=False,\n",
              "                                                                  fit_intercept=True,\n",
              "                                                                  intercept_scaling=1,\n",
              "                                                                  l1_ratio=None,\n",
              "                                                                  max_iter=250,\n",
              "                                                                  multi_class='auto',\n",
              "                                                                  n_jobs=None,\n",
              "                                                                  penalty='l2',\n",
              "                                                                  random_state=0,\n",
              "                                                                  solver='lbfgs',\n",
              "                                                                  tol=0.0001,\n",
              "                                                                  verbose=0,\n",
              "                                                                  warm_start=False),\n",
              "                                     n_jobs=None))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IStdEzcHm8lZ",
        "outputId": "98908eac-d87d-4867-b354-2df9ea836dbd"
      },
      "source": [
        "# Test accuracy\r\n",
        "y_pred = model.predict(X_test)\r\n",
        "f1_score(y_test, y_pred, average='micro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7995218579234973"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}